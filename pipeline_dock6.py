"""
Pipeline d‚Äôanalyse de l‚Äôeffet fondateur (DOCK6)
------------------------------------------------
Auteur     : Patrick MUNIER
Version    : 1.0
Description: Ce script ex√©cute une analyse g√©n√©tique compl√®te √† partir de fichiers SNP pour d√©tecter
             un effet fondateur autour d‚Äôune mutation. Il utilise PLINK, KING, Adegenet et Gamma pour :
             - Identifier les segments ROH
             - D√©tecter les liens familiaux (IBD)
             - Analyser la structure populationnelle
             - Dater la mutation par d√©s√©quilibre de liaison
             Il g√©n√®re √©galement des fichiers d‚Äôentr√©e, graphiques et rapports PDF.

D√©pendances:
 - Python 3.x
 - pandas
 - matplotlib
 - fpdf
 - PLINK, KING, R (adegenet), Gamma (install√©s s√©par√©ment)
 - Fichiers d‚Äôentr√©e: .raw, .map, .ped, .bed, .bim, .fam

Fichiers de sortie g√©n√©r√©s automatiquement:
 - `output/pipeline_execution.log` : journal complet de l'ex√©cution
 - `output/roh_results/` : fichiers PLINK de segments ROH
 - `output/ibd_results/` : r√©sultats KING (liens familiaux, fichiers .kin)
 - `output/adegenet_results/` :
     - Graphiques .png g√©n√©r√©s par adegenet
     - `rapport_graphique_adegenet.pdf` : rapport compilant tous les graphiques
 - `output/gamma_results/` :
     - `genotype_data.gamma_input.txt` : fichier d'entr√©e pour Gamma
     - `frequence_allelique.png` : graphique des fr√©quences all√©liques
     - `rapport_gamma.pdf` : rapport PDF incluant statistiques et graphe

Usage :
    python pipeline_dock6.py
"""

import subprocess
import os
import platform
import logging
import pandas as pd
import matplotlib.pyplot as plt
from fpdf import FPDF

# Chemins globaux dynamiques
base_dir = os.path.abspath(os.path.dirname(__file__))
input_data = os.path.join(base_dir, "../data/input/genotype_data")
output_data = os.path.join(base_dir, "../data/output")
script_dir = os.path.join(base_dir, "../scripts")
log_file = os.path.join(output_data, "pipeline_execution.log")

# Configuration du mode debug avec sortie vers fichier log
DEBUG = True
logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)

# Assure que tous les dossiers existent
os.makedirs(output_data, exist_ok=True)

# D√©tection du syst√®me d'exploitation
is_macos = platform.system() == "Darwin"
is_linux = platform.system() == "Linux"

# V√©rifie que les scripts existent
# ---------------------------------------------------------
def check_script_exists(script_path):
    if not os.path.isfile(script_path):
        logging.critical(f"Le fichier requis est introuvable : {script_path}")
        raise FileNotFoundError(script_path)

# Ex√©cution des commandes externes via subprocess
# ---------------------------------------------------------
def run_command(cmd):
    logging.debug(f"Ex√©cution de la commande : {cmd}")
    try:
        result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        logging.debug(result.stdout)
    except subprocess.CalledProcessError as e:
        logging.error(f"Erreur dans la commande : {cmd}\n{e.stderr}")
        raise

# G√©n√®re le fichier gamma_input.txt, un graphique et un rapport PDF
# ---------------------------------------------------------
def generate_gamma_input(raw_file_path, map_file_path, output_file):
    logging.info("G√©n√©ration du fichier gamma_input.txt")

    # V√©rifie l'existence des fichiers source
    if not os.path.exists(raw_file_path) or not os.path.exists(map_file_path):
        logging.critical("Fichiers .raw ou .map introuvables pour la g√©n√©ration.")
        raise FileNotFoundError("Fichier requis manquant.")

    # Lecture du fichier .raw contenant les g√©notypes (cod√©s 0, 1, 2)
    raw_df = pd.read_csv(raw_file_path, delim_whitespace=True)
    # Lecture du fichier .map avec les positions g√©n√©tiques des SNPs
    map_df = pd.read_csv(map_file_path, delim_whitespace=True, header=None,
                         names=["chr", "snp", "gen_dist", "phys_pos"])

    # S√©lectionne les colonnes correspondant aux SNPs (exclut les m√©tadonn√©es)
    snps = [col for col in raw_df.columns if col not in ["FID", "IID", "PAT", "MAT", "SEX", "PHENOTYPE"]]
    data = []

    # Parcourt chaque SNP pour calculer la fr√©quence all√©lique et le filtrer
    for snp in snps:
        map_row = map_df[map_df['snp'] == snp]
        if map_row.empty:
            continue
        cM = map_row.iloc[0]['gen_dist']
        allele_sum = raw_df[snp].sum()
        allele_freq = allele_sum / (2 * len(raw_df))  # Fr√©quence de l'all√®le 1
        if 0 < allele_freq < 1 and raw_df[snp].var() > 0:
            data.append((snp, cM, allele_freq))

    # Cr√©e le DataFrame final et sauvegarde au format .txt (TSV)
    gamma_df = pd.DataFrame(data, columns=["SNP", "Position_cM", "Freq_All√®le_1"])
    gamma_df.to_csv(output_file, sep='\t', index=False)
    logging.info(f"Fichier gamma_input.txt g√©n√©r√© : {output_file}")

    # G√©n√®re un graphique de la fr√©quence all√©lique par position
    plt.figure(figsize=(10, 5))
    plt.scatter(gamma_df['Position_cM'], gamma_df['Freq_All√®le_1'], alpha=0.6, edgecolors='k')
    plt.title("Fr√©quences all√©liques des SNPs retenus pour Gamma")
    plt.xlabel("Position (cM)")
    plt.ylabel("Fr√©quence de l'all√®le 1")
    plt.grid(True)
    plot_path = os.path.join(os.path.dirname(output_file), "frequence_allelique.png")
    plt.savefig(plot_path)
    plt.close()
    logging.info(f"Graphique des fr√©quences all√©liques sauvegard√© : {plot_path}")

    # Calcule les statistiques descriptives pour le PDF
    n_snps = len(gamma_df)
    freq_mean = gamma_df['Freq_All√®le_1'].mean()
    freq_min = gamma_df['Freq_All√®le_1'].min()
    freq_max = gamma_df['Freq_All√®le_1'].max()

    # G√©n√®re un rapport PDF contenant le graphique et les statistiques
    pdf_path = os.path.join(os.path.dirname(output_file), "rapport_gamma.pdf")
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="Rapport - Fr√©quences all√©liques pour Gamma", ln=True, align='C')
    pdf.ln(10)
    pdf.image(plot_path, x=10, w=180)
    pdf.ln(10)
    pdf.set_font("Arial", size=11)
    pdf.multi_cell(0, 10, txt=(
        f"Nombre total de SNPs informatifs : {n_snps}\n"
        f"Fr√©quence moyenne de l'all√®le 1 : {freq_mean:.3f}\n"
        f"Fr√©quence minimale : {freq_min:.3f}\n"
        f"Fr√©quence maximale : {freq_max:.3f}"
    ))
    pdf.output(pdf_path)
    logging.info(f"Rapport PDF g√©n√©r√© : {pdf_path}")

# √âtapes du pipeline
# ---------------------------------------------------------

def run_roh():
    # Lance l'√©tape ROH avec PLINK
    logging.info("√âtape 1 : Analyse ROH avec PLINK")
    cmd = f"bash {os.path.join(script_dir, 'commands_pipeline_dock6.sh')}"
    run_command(cmd)

def run_ibd():
    # Lance l'√©tape IBD avec KING
    logging.info("√âtape 2 : Analyse IBD avec KING")
    cmd = f"bash {os.path.join(script_dir, 'commands_pipeline_dock6.sh')}"
    run_command(cmd)

def run_adegenet():
    # Lance l'analyse de structure avec R et adegenet
    logging.info("√âtape 3 : Analyse de structure avec adegenet")
    cmd = f"Rscript {os.path.join(script_dir, 'adegenet_analysis.R')}"
    run_command(cmd)

    # D√©place tous les fichiers .png et .pdf g√©n√©r√©s dans le dossier de sortie d√©di√©
    adegenet_output_dir = os.path.join(output_data, "adegenet_results")
    os.makedirs(adegenet_output_dir, exist_ok=True)

    for file in os.listdir(script_dir):
        if file.endswith(".png") or file.endswith(".pdf"):
            src = os.path.join(script_dir, file)
            dst = os.path.join(adegenet_output_dir, file)
            os.rename(src, dst)
            logging.info(f"Graphique adegenet d√©plac√© : {dst}")

    # G√©n√®re un rapport PDF regroupant tous les graphiques .png
    from fpdf import FPDF
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="Rapport des graphiques Adegenet", ln=True, align='C')
    pdf.ln(10)

    added = 0
    for file in sorted(os.listdir(adegenet_output_dir)):
        if file.endswith(".png"):
            file_path = os.path.join(adegenet_output_dir, file)
            pdf.add_page()
            pdf.cell(0, 10, file, ln=True)
            pdf.image(file_path, x=10, w=180)
            added += 1

    if added > 0:
        pdf_output_path = os.path.join(adegenet_output_dir, "rapport_graphique_adegenet.pdf")
        pdf.output(pdf_output_path)
        logging.info(f"Rapport PDF des graphiques Adegenet g√©n√©r√© : {pdf_output_path}")

def run_gamma():
    # G√©n√®re les fichiers pour Gamma, le graphique et le rapport, puis ex√©cute Gamma
    logging.info("√âtape 4 : Datation avec Gamma")
    raw_file = input_data + ".raw"
    map_file = input_data + ".map"
    gamma_input = os.path.join(os.path.dirname(input_data), "genotype_data.gamma_input.txt")
    generate_gamma_input(raw_file, map_file, gamma_input)
    cmd = f"bash {os.path.join(script_dir, 'commands_pipeline_dock6.sh')}"
    run_command(cmd)

# Fonction principale s√©curis√©e
# ---------------------------------------------------------

def main():
    logging.info("üî¨ D√©marrage du pipeline d'analyse de l'effet fondateur (DOCK6)")
    logging.info("=" * 60)
    try:
        run_roh()
        run_ibd()
        run_adegenet()
        run_gamma()
    except Exception as e:
        logging.critical(f"Pipeline interrompu : {e}")
    else:
        logging.info("‚úÖ Pipeline termin√© avec succ√®s !")
    finally:
        logging.info("üß™ Analyse finalis√©e")

import argparse

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Pipeline d'analyse g√©n√©tique pour effet fondateur (DOCK6)")
    parser.add_argument('--version', action='version', version='DOCK6 Pipeline 1.0')
    parser.add_argument('--step', type=str, choices=['roh', 'ibd', 'adegenet', 'gamma', 'all'], default='all',
                        help='√âtape √† ex√©cuter : roh, ibd, adegenet, gamma, ou all')
    parser.add_argument('--debug', action='store_true', help='Activer le mode d√©bogage')
    parser.add_argument('--resume', action='store_true', help='Reprendre une ex√©cution pr√©c√©dente (non impl√©ment√©)')
    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        logging.debug("Mode DEBUG activ√©")

    if args.step == 'roh':
        run_roh()
    elif args.step == 'ibd':
        run_ibd()
    elif args.step == 'adegenet':
        run_adegenet()
    elif args.step == 'gamma':
        run_gamma()
    elif args.step == 'all':
        main()
